{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load data\n",
    "df1 = pd.read_csv(\"../data/old.csv\")\n",
    "df2 = pd.read_csv(\"../data/new_labeled_data.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True).drop_duplicates()\n",
    "df = df.reset_index().rename(columns={'index': 'original_index'})\n",
    "\n",
    "# Subset (90%)\n",
    "df_subset, _ = train_test_split(\n",
    "    df, train_size=0.9, stratify=df['is_fraud'], random_state=42\n",
    ")\n",
    "\n",
    "# Feature selection\n",
    "selected_features = [\n",
    "    'original_index', 'first', 'last', 'cc_num', 'amt', 'gender', 'city', 'state',\n",
    "    'zip', 'dob', 'job', 'category', 'is_fraud'\n",
    "]\n",
    "df_selected = df_subset[selected_features].copy()\n",
    "\n",
    "# Feature engineering\n",
    "df_selected['dob'] = pd.to_datetime(df_selected['dob'], errors='coerce')\n",
    "df_selected['age'] = (pd.Timestamp.now() - df_selected['dob']).dt.days / 365.25\n",
    "df_selected.drop(['dob'], axis=1, inplace=True)\n",
    "\n",
    "# Fill numeric\n",
    "df_selected['cc_num'] = pd.to_numeric(df_selected['cc_num'], errors='coerce').fillna(0)\n",
    "df_selected['amt'] = pd.to_numeric(df_selected['amt'], errors='coerce').fillna(0)\n",
    "df_selected['zip'] = pd.to_numeric(df_selected['zip'], errors='coerce').fillna(0)\n",
    "df_selected['age'] = df_selected['age'].fillna(df_selected['age'].median())\n",
    "\n",
    "# Encode categoricals\n",
    "categorical_columns = ['first', 'last', 'gender', 'city', 'state', 'job', 'category']\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    df_selected[col] = df_selected[col].astype(str).fillna('unknown')\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df_selected[col].unique()) + ['unknown'])\n",
    "    df_selected[col] = df_selected[col].apply(lambda x: x if x in le.classes_ else 'unknown')\n",
    "    df_selected[col] = le.transform(df_selected[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split features & target\n",
    "X = df_selected.drop(['is_fraud', 'original_index'], axis=1)\n",
    "y = df_selected['is_fraud']\n",
    "original_indices = df_selected['original_index']\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "    X_scaled, y, original_indices, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Final model (from best params)\n",
    "model = XGBClassifier(\n",
    "    colsample_bytree=0.7569998494820424,\n",
    "    learning_rate=0.24737555188414592,\n",
    "    max_depth=6,\n",
    "    min_child_weight=4,\n",
    "    n_estimators=311,\n",
    "    subsample=0.9570351922786028,\n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',\n",
    "    device='cuda'\n",
    ")\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best threshold (based on earlier evaluation)\n",
    "best_threshold = 0.85\n",
    "\n",
    "# Save model and artifacts\n",
    "model.save_model('credit_fraud_xgboost_model.json')\n",
    "with open('best_threshold.pkl', 'wb') as f:\n",
    "    pickle.dump(best_threshold, f)\n",
    "with open('scaler_xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('label_encoders_xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(\"âœ… Model and preprocessing artifacts saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
