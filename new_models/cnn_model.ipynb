{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.combine import SMOTEENN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "import pickle\n",
    "\n",
    "# Load the full dataset\n",
    "df1 = pd.read_csv(\"../data/old.csv\")\n",
    "df2 = pd.read_csv(\"../data/new_labeled_data.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Select a subset of the data (e.g., 40% of the dataset)\n",
    "subset_fraction = 0.90  # Adjust as needed\n",
    "df_subset, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=subset_fraction,\n",
    "    stratify=df['is_fraud'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Preserve original indices\n",
    "df_subset = df_subset.reset_index(drop=False).rename(columns={'index': 'original_index'})\n",
    "\n",
    "# Select specified features\n",
    "selected_features = [\n",
    "    'original_index', 'first', 'last', 'cc_num', 'amt', 'gender', 'city', 'state',\n",
    "    'zip', 'dob', 'job', 'category', 'is_fraud'\n",
    "]\n",
    "df_selected = df_subset[selected_features].copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "# Calculate age from dob\n",
    "df_selected['dob'] = pd.to_datetime(df_selected['dob'])\n",
    "df_selected['age'] = (pd.Timestamp.now() - df_selected['dob']).dt.days / 365.25\n",
    "\n",
    "# Drop dob column\n",
    "df_selected = df_selected.drop(['dob'], axis=1)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['first', 'last', 'gender', 'city', 'state', 'job', 'category']\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[column] = le.fit_transform(df_selected[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separate features, target, and indices\n",
    "X = df_selected.drop(['is_fraud', 'original_index'], axis=1)\n",
    "y = df_selected['is_fraud']\n",
    "indices = df_selected['original_index']\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data (before oversampling)\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "    X_scaled, y, indices, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE + ENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reshape data for CNN (samples, timesteps, features)\n",
    "X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], X_train_resampled.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_resampled.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_resampled, y_train_resampled,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Test on 100 fraud examples\n",
    "# Create a DataFrame with test data, labels, and indices\n",
    "test_df = pd.DataFrame({\n",
    "    'original_index': indices_test,\n",
    "    'true_label': y_test,\n",
    "    'features': list(X_test)\n",
    "})\n",
    "\n",
    "# Filter for fraud cases\n",
    "fraud_test_df = test_df[test_df['true_label'] == 1]\n",
    "\n",
    "# Select up to 100 fraud examples\n",
    "fraud_sample = fraud_test_df.head(100)\n",
    "if len(fraud_sample) < 100:\n",
    "    print(f\"Warning: Only {len(fraud_sample)} fraud cases available in test set.\")\n",
    "\n",
    "# Prepare features for prediction\n",
    "fraud_features = np.array(fraud_sample['features'].tolist())\n",
    "fraud_features_reshaped = fraud_features.reshape((fraud_features.shape[0], fraud_features.shape[1], 1))\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(fraud_features_reshaped)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'original_index': fraud_sample['original_index'],\n",
    "    'true_label': fraud_sample['true_label'],\n",
    "    'predicted_label': predicted_classes,\n",
    "    'prediction_probability': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Calculate accuracy for fraud cases\n",
    "fraud_accuracy = (results_df['true_label'] == results_df['predicted_label']).mean()\n",
    "print(f\"\\nAccuracy on {len(results_df)} fraud cases: {fraud_accuracy:.4f}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDetailed Results for Fraud Cases:\")\n",
    "print(results_df[['original_index', 'true_label', 'predicted_label', 'prediction_probability']])\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('fraud_test_results.csv', index=False)\n",
    "print(\"\\nFraud test results saved to 'fraud_test_results.csv'\")\n",
    "\n",
    "# Save the model\n",
    "model.save('credit_fraud_cnn_model_resampled.h5')\n",
    "\n",
    "# Save the scaler and label encoders\n",
    "with open('scaler_resampled.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('label_encoders_resampled.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(\"Model and preprocessing objects saved successfully with SMOTE + ENN!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
